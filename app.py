from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import fitz  # PyMuPDF
import os
import tempfile
import zipfile
import json
from werkzeug.utils import secure_filename
import uuid
from datetime import datetime
import shutil
import threading
import time
import queue
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import subprocess

app = Flask(__name__)
CORS(app)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì„¤ì •
UPLOAD_FOLDER = 'pdfs'
PROCESSED_FOLDER = 'masked-pdfs'
MAX_FILE_SIZE = 16 * 1024 * 1024  # 16MB
ALLOWED_EXTENSIONS = {'pdf'}
MAX_WORKERS = 4  # ë™ì‹œ ì²˜ë¦¬ ìŠ¤ë ˆë“œ ìˆ˜
BATCH_SIZE = 50  # ë°°ì¹˜ í¬ê¸°

# ì‘ì—… ìƒíƒœ ì¶”ì 
job_status = {}
job_lock = threading.Lock()

# í´ë” ìƒì„±
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(PROCESSED_FOLDER, exist_ok=True)

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def update_job_status(job_id, status, progress=0, message="", error=None):
    """ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸"""
    with job_lock:
        job_status[job_id] = {
            'status': status,  # 'pending', 'running', 'completed', 'failed'
            'progress': progress,  # 0-100
            'message': message,
            'error': error,
            'timestamp': datetime.now().isoformat()
        }

def redact_pdf_batch(files_batch, redaction_areas, job_id):
    """PDF ë°°ì¹˜ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬"""
    processed_files = []
    
    for i, (input_path, output_path, filename) in enumerate(files_batch):
        try:
            # PDF ë§ˆìŠ¤í‚¹ ì²˜ë¦¬
            doc = fitz.open(input_path)
            
            for page in doc:
                for area in redaction_areas:
                    rect = fitz.Rect(area['x1'], area['y1'], area['x2'], area['y2'])
                    page.add_redact_annot(rect)
                page.apply_redactions()
            
            doc.save(output_path)
            doc.close()
            
            processed_files.append({
                'original_name': filename,
                'masked_name': os.path.basename(output_path),
                'size': os.path.getsize(output_path)
            })
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress = ((i + 1) / len(files_batch)) * 100
            update_job_status(job_id, 'running', progress, f'ë°°ì¹˜ ì²˜ë¦¬ ì¤‘: {i+1}/{len(files_batch)}')
            
        except Exception as e:
            logger.error(f"íŒŒì¼ {filename} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            continue
    
    return processed_files

def process_large_masking(pdf_files, redaction_areas, job_id):
    """ëŒ€ìš©ëŸ‰ íŒŒì¼ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬"""
    try:
        update_job_status(job_id, 'running', 0, 'ë§ˆìŠ¤í‚¹ ì‘ì—… ì‹œì‘')
        
        # ê¸°ì¡´ ë§ˆìŠ¤í‚¹ íŒŒì¼ë“¤ ì •ë¦¬
        if os.path.exists(PROCESSED_FOLDER):
            for file in os.listdir(PROCESSED_FOLDER):
                if file.endswith('.pdf'):
                    os.remove(os.path.join(PROCESSED_FOLDER, file))
        
        # íŒŒì¼ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°
        batches = [pdf_files[i:i + BATCH_SIZE] for i in range(0, len(pdf_files), BATCH_SIZE)]
        total_files = len(pdf_files)
        processed_count = 0
        all_processed_files = []
        file_mapping = []
        
        # ê° ë°°ì¹˜ë¥¼ ìˆœì°¨ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
        for batch_idx, batch in enumerate(batches):
            update_job_status(job_id, 'running', 
                            (batch_idx / len(batches)) * 90,  # 90%ê¹Œì§€ëŠ” ì²˜ë¦¬ ê³¼ì •
                            f'ë°°ì¹˜ {batch_idx + 1}/{len(batches)} ì²˜ë¦¬ ì¤‘')
            
            # ë°°ì¹˜ìš© íŒŒì¼ ê²½ë¡œ ì¤€ë¹„
            batch_files = []
            for filename in batch:
                file_number = processed_count + len(batch_files) + 1
                input_path = os.path.join(UPLOAD_FOLDER, filename)
                output_filename = f"{file_number}.pdf"
                output_path = os.path.join(PROCESSED_FOLDER, output_filename)
                batch_files.append((input_path, output_path, filename))
            
            # ë°°ì¹˜ ì²˜ë¦¬
            batch_result = redact_pdf_batch(batch_files, redaction_areas, job_id)
            all_processed_files.extend(batch_result)
            
            # ë§¤í•‘ ì •ë³´ ìƒì„±
            for i, filename in enumerate(batch):
                file_number = processed_count + i + 1
                file_mapping.append({
                    'number': file_number,
                    'original_name': filename,
                    'masked_name': f"{file_number}.pdf"
                })
            
            processed_count += len(batch)
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            overall_progress = (processed_count / total_files) * 90
            update_job_status(job_id, 'running', overall_progress, 
                            f'ì²˜ë¦¬ ì™„ë£Œ: {processed_count}/{total_files}')
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ìœ„í•œ ì ì‹œ ëŒ€ê¸°
            time.sleep(0.1)
        
        # ë§¤í•‘ ì •ë³´ ì €ì¥
        mapping_path = os.path.join(PROCESSED_FOLDER, 'file_mapping.json')
        with open(mapping_path, 'w', encoding='utf-8') as f:
            json.dump(file_mapping, f, ensure_ascii=False, indent=2)
        
        update_job_status(job_id, 'completed', 100, 
                         f'ë§ˆìŠ¤í‚¹ ì™„ë£Œ: {len(all_processed_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ë¨')
        
        return {
            'processed_files': all_processed_files,
            'file_mapping': file_mapping,
            'total_processed': len(all_processed_files)
        }
        
    except Exception as e:
        update_job_status(job_id, 'failed', 0, '', str(e))
        raise

@app.route('/')
def index():
    return '''
    <!DOCTYPE html>
    <html>
    <head>
        <title>ëŒ€ìš©ëŸ‰ PDF ì²˜ë¦¬ ì„œë²„</title>
    </head>
    <body>
        <h1>ğŸš€ ëŒ€ìš©ëŸ‰ PDF í†µí•© ì²˜ë¦¬ ë°±ì—”ë“œ ì„œë²„</h1>
        <p>ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ í–¥ìƒëœ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤!</p>
        <p>ë°°ì¹˜ ì²˜ë¦¬ ë° ë¹„ë™ê¸° ì‘ì—…ì„ ì§€ì›í•©ë‹ˆë‹¤.</p>
    </body>
    </html>
    '''

@app.route('/upload', methods=['POST'])
def upload_files():
    """íŒŒì¼ ì—…ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
    try:
        if 'files' not in request.files:
            return jsonify({'error': 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400
        
        files = request.files.getlist('files')
        if not files or files[0].filename == '':
            return jsonify({'error': 'ì„ íƒëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400
        
        # ê¸°ì¡´ íŒŒì¼ë“¤ ì •ë¦¬
        if os.path.exists(UPLOAD_FOLDER):
            for file in os.listdir(UPLOAD_FOLDER):
                if file.endswith('.pdf'):
                    os.remove(os.path.join(UPLOAD_FOLDER, file))
        
        uploaded_files = []
        total_size = 0
        
        # íŒŒì¼ í¬ê¸° ë° ê°œìˆ˜ ì²´í¬
        for file in files:
            if file and allowed_file(file.filename):
                file_size = len(file.read())
                if file_size > MAX_FILE_SIZE:
                    return jsonify({'error': f'{file.filename} íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. (ìµœëŒ€ 16MB)'}), 400
                total_size += file_size
                file.seek(0)
        
        # ì´ í¬ê¸° ì²´í¬ (10GB ì œí•œ)
        if total_size > 10 * 1024 * 1024 * 1024:
            return jsonify({'error': 'ì´ íŒŒì¼ í¬ê¸°ê°€ 10GBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.'}), 400
        
        # íŒŒì¼ ì €ì¥ (ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹)
        for file in files:
            if file and allowed_file(file.filename):
                filename = file.filename
                file_path = os.path.join(UPLOAD_FOLDER, filename)
                
                # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì €ì¥ (ë©”ëª¨ë¦¬ ì ˆì•½)
                with open(file_path, 'wb') as f:
                    while True:
                        chunk = file.read(8192)  # 8KB ì²­í¬
                        if not chunk:
                            break
                        f.write(chunk)
                
                uploaded_files.append({
                    'filename': filename,
                    'size': os.path.getsize(file_path)
                })
        
        # íŒŒì¼ëª… ìˆœì„œë¡œ ì •ë ¬
        uploaded_files.sort(key=lambda x: x['filename'])
        
        return jsonify({
            'success': True,
            'session_id': 'batch_session',
            'files': uploaded_files,
            'count': len(uploaded_files),
            'total_size': total_size
        })
        
    except Exception as e:
        return jsonify({'error': f'ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/mask-async', methods=['POST'])
def mask_pdfs_async():
    """ë¹„ë™ê¸° PDF ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ ì‹œì‘"""
    try:
        data = request.json
        masking_areas = data.get('masking_areas', [])
        
        if not masking_areas:
            return jsonify({'error': 'ë§ˆìŠ¤í‚¹ ì˜ì—­ì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
        
        if not os.path.exists(UPLOAD_FOLDER):
            return jsonify({'error': 'ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400
        
        # íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        pdf_files = [f for f in os.listdir(UPLOAD_FOLDER) if f.lower().endswith('.pdf')]
        pdf_files.sort()
        
        if not pdf_files:
            return jsonify({'error': 'ì²˜ë¦¬í•  PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400
        
        # ì‘ì—… ID ìƒì„±
        job_id = str(uuid.uuid4())
        update_job_status(job_id, 'pending', 0, f'{len(pdf_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘')
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œì‘
        def background_task():
            try:
                result = process_large_masking(pdf_files, masking_areas, job_id)
                # ê²°ê³¼ë¥¼ job_statusì— ì €ì¥
                with job_lock:
                    job_status[job_id]['result'] = result
            except Exception as e:
                update_job_status(job_id, 'failed', 0, '', str(e))
        
        thread = threading.Thread(target=background_task)
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'success': True,
            'job_id': job_id,
            'message': f'{len(pdf_files)}ê°œ íŒŒì¼ì˜ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'estimated_time': f'{len(pdf_files) * 2} ì´ˆ ì˜ˆìƒ'
        })
        
    except Exception as e:
        return jsonify({'error': f'ì‘ì—… ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/job-status/<job_id>')
def get_job_status(job_id):
    """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    with job_lock:
        if job_id not in job_status:
            return jsonify({'error': 'ì‘ì—… IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
        return jsonify(job_status[job_id])

@app.route('/run-gemini-ocr-async', methods=['POST'])
def run_gemini_ocr_async():
    """ë¹„ë™ê¸° Gemini OCR ì²˜ë¦¬"""
    try:
        if not os.path.exists(PROCESSED_FOLDER):
            return jsonify({'error': 'ë§ˆìŠ¤í‚¹ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400
        
        # ì‘ì—… ID ìƒì„±
        job_id = str(uuid.uuid4())
        update_job_status(job_id, 'pending', 0, 'OCR ì²˜ë¦¬ ëŒ€ê¸° ì¤‘')
        
        def background_ocr():
            try:
                update_job_status(job_id, 'running', 10, 'Gemini OCR ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘...')
                
                # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
                env = os.environ.copy()
                env['PYTHONIOENCODING'] = 'utf-8'
                
                # ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
                result = subprocess.run(
                    ['python', 'gemini-pdf-ocr-genai.py'], 
                    capture_output=True, 
                    text=True, 
                    timeout=3600,  # 1ì‹œê°„ íƒ€ì„ì•„ì›ƒ
                    encoding='utf-8',
                    env=env
                )
                
                if result.returncode == 0:
                    update_job_status(job_id, 'completed', 100, 'OCR ì²˜ë¦¬ ì™„ë£Œ')
                    with job_lock:
                        job_status[job_id]['result'] = {
                            'output': result.stdout,
                            'success': True
                        }
                else:
                    update_job_status(job_id, 'failed', 0, 'OCR ì²˜ë¦¬ ì‹¤íŒ¨', result.stderr)
                    
            except subprocess.TimeoutExpired:
                update_job_status(job_id, 'failed', 0, 'OCR ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼', '1ì‹œê°„ íƒ€ì„ì•„ì›ƒ')
            except Exception as e:
                update_job_status(job_id, 'failed', 0, 'OCR ì²˜ë¦¬ ì˜¤ë¥˜', str(e))
        
        thread = threading.Thread(target=background_ocr)
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'success': True,
            'job_id': job_id,
            'message': 'OCR ì²˜ë¦¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. (ìµœëŒ€ 1ì‹œê°„ ì†Œìš”)'
        })
        
    except Exception as e:
        return jsonify({'error': f'OCR ì‘ì—… ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/extract-info', methods=['POST'])
def extract_personal_info():
    """ê°œì¸ì •ë³´ ì¶”ì¶œ (ê¸°ì¡´ê³¼ ë™ì¼)"""
    try:
        if not os.path.exists(UPLOAD_FOLDER):
            return jsonify({'error': 'ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400
        
        pdf_files = [f for f in os.listdir(UPLOAD_FOLDER) if f.lower().endswith('.pdf')]
        pdf_files.sort()
        
        personal_info = []
        
        for i, filename in enumerate(pdf_files, 1):
            file_base = filename.replace('.pdf', '')
            parts = file_base.split('_')
            
            if len(parts) >= 2:
                name = parts[0]
                birth_date = parts[1]
                
                if len(birth_date) == 6 or len(birth_date) == 8:
                    if birth_date.isdigit():
                        personal_info.append({
                            'order': i,
                            'name': name,
                            'birth_date': birth_date,
                            'original_filename': filename
                        })
        
        return jsonify({
            'success': True,
            'session_id': 'batch_session',
            'personal_info': personal_info,
            'total_extracted': len(personal_info)
        })
        
    except Exception as e:
        return jsonify({'error': f'ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/download-masked/<session_id>')
def download_masked_files(session_id):
    """ë§ˆìŠ¤í‚¹ëœ íŒŒì¼ë“¤ì„ ZIPìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ"""
    try:
        if not os.path.exists(PROCESSED_FOLDER):
            return jsonify({'error': 'ë§ˆìŠ¤í‚¹ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400
        
        zip_path = os.path.join(tempfile.gettempdir(), 
                               f'masked_files_{datetime.now().strftime("%Y%m%d_%H%M%S")}.zip')
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for filename in os.listdir(PROCESSED_FOLDER):
                if filename.endswith('.pdf'):
                    file_path = os.path.join(PROCESSED_FOLDER, filename)
                    zipf.write(file_path, filename)
            
            mapping_path = os.path.join(PROCESSED_FOLDER, 'file_mapping.json')
            if os.path.exists(mapping_path):
                zipf.write(mapping_path, 'file_mapping.json')
        
        return send_file(
            zip_path,
            as_attachment=True,
            download_name=f'masked_pdfs_{datetime.now().strftime("%Y%m%d_%H%M%S")}.zip',
            mimetype='application/zip'
        )
        
    except Exception as e:
        return jsonify({'error': f'ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/health')
def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'version': '2.0.0 (Enhanced)',
        'max_workers': MAX_WORKERS,
        'batch_size': BATCH_SIZE
    })

if __name__ == '__main__':
    print("ğŸš€ ëŒ€ìš©ëŸ‰ PDF í†µí•© ì²˜ë¦¬ ë°±ì—”ë“œ ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print(f"ğŸ“‚ ì—…ë¡œë“œ í´ë”: {UPLOAD_FOLDER}")
    print(f"ğŸ“‚ ì²˜ë¦¬ í´ë”: {PROCESSED_FOLDER}")
    print(f"âš™ï¸ ìµœëŒ€ ë™ì‹œ ì²˜ë¦¬: {MAX_WORKERS} ìŠ¤ë ˆë“œ")
    print(f"ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE} íŒŒì¼")
    print("ğŸŒ ì„œë²„ ì£¼ì†Œ: http://localhost:5000")
    
    app.run(debug=True, host='0.0.0.0', port=5000, threaded=True)